{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy.io import arff\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_data_train = scipy.io.arff.loadarff(\"/home/karim/Documents/research/MLML datasets/emotions/emotions-train.arff\")\n",
    "emotions_data_test = scipy.io.arff.loadarff(\"/home/karim/Documents/research/MLML datasets/emotions/emotions-test.arff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples is: 391\n",
      "Number of test samples is: 202\n"
     ]
    }
   ],
   "source": [
    "features_labels = emotions_data_train[0]\n",
    "features_labels_df = pd.DataFrame(features_labels)\n",
    "print(\"Number of training samples is: {}\".format(len(emotions_data[0])))\n",
    "\n",
    "features_labels_test = emotions_data_test[0]\n",
    "features_labels__test_df = pd.DataFrame(features_labels_test)\n",
    "print(\"Number of test samples is: {}\".format(len(features_labels__test_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features_labels_df.values[:,:-6]\n",
    "labels = features_labels_df.values[:,-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "input_shape = 72\n",
    "output_shape = 6\n",
    "hidden_layer_1_shape = 48\n",
    "hidden_layer_2_shape = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "code_folding": [
     0,
     5,
     11
    ]
   },
   "outputs": [],
   "source": [
    "def get_weights(shape):\n",
    "    w = tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "    #variable_summaries(w)\n",
    "    return w\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    b = tf.Variable(initial)\n",
    "    #variable_summaries(b)\n",
    "    return b\n",
    "\n",
    "def full_layer(input, size):\n",
    "    in_size = int(input.get_shape()[1])\n",
    "    W = get_weights([in_size, size])\n",
    "    b = bias_variable([size])\n",
    "    return tf.matmul(input, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a 2 layers network to train \n",
    "y = tf.placeholder(tf.float32, [None, output_shape], name=\"true_labels\")\n",
    "x_input = tf.placeholder(tf.float32, [None,input_shape],name=\"input_layer\")\n",
    "h1 = tf.nn.relu(full_layer(x_input, hidden_layer_1_shape))\n",
    "h2 = tf.nn.relu(full_layer(h1, hidden_layer_2_shape))\n",
    "h3 = tf.nn.relu(full_layer(h2, hidden_layer_2_shape))\n",
    "h4 = tf.nn.relu(full_layer(h3, hidden_layer_2_shape))\n",
    "logits = full_layer(h4,output_shape)\n",
    "output = tf.nn.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "# Learning rate decay\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "learning_rate = tf.train.exponential_decay(learning_rate=0.1, global_step=global_step, decay_steps=1000,\n",
    "                                          decay_rate=0.95,staircase=True)\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "correct_prediction = tf.equal(tf.round(output), y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #500 Loss: 0.6054 accuracy: 0.6974\n",
      "Epoch #1000 Loss: 0.6050 accuracy: 0.6978\n",
      "Epoch #1500 Loss: 0.6046 accuracy: 0.6978\n",
      "Epoch #2000 Loss: 0.6042 accuracy: 0.6978\n",
      "Epoch #2500 Loss: 0.6038 accuracy: 0.6978\n",
      "Epoch #3000 Loss: 0.6034 accuracy: 0.6978\n",
      "Epoch #3500 Loss: 0.6030 accuracy: 0.6978\n",
      "Epoch #4000 Loss: 0.6024 accuracy: 0.6978\n",
      "Epoch #4500 Loss: 0.6021 accuracy: 0.6978\n",
      "Epoch #5000 Loss: 0.6017 accuracy: 0.6978\n",
      "Epoch #5500 Loss: 0.6013 accuracy: 0.6978\n",
      "Epoch #6000 Loss: 0.6009 accuracy: 0.6978\n",
      "Epoch #6500 Loss: 0.6004 accuracy: 0.6978\n",
      "Epoch #7000 Loss: 0.5999 accuracy: 0.6978\n",
      "Epoch #7500 Loss: 0.5993 accuracy: 0.6978\n",
      "Epoch #8000 Loss: 0.5985 accuracy: 0.6978\n",
      "Epoch #8500 Loss: 0.5974 accuracy: 0.6982\n",
      "Epoch #9000 Loss: 0.5959 accuracy: 0.6982\n",
      "Epoch #9500 Loss: 0.5937 accuracy: 0.6974\n",
      "Epoch #10000 Loss: 0.5898 accuracy: 0.7003\n",
      "Epoch #10500 Loss: 0.5808 accuracy: 0.7106\n",
      "Epoch #11000 Loss: 0.5724 accuracy: 0.7204\n",
      "Epoch #11500 Loss: 0.5732 accuracy: 0.7199\n",
      "Epoch #12000 Loss: 0.5646 accuracy: 0.7234\n",
      "Epoch #12500 Loss: 0.5519 accuracy: 0.7280\n",
      "Epoch #13000 Loss: 0.5486 accuracy: 0.7276\n",
      "Epoch #13500 Loss: 0.5424 accuracy: 0.7298\n",
      "Epoch #14000 Loss: 0.5363 accuracy: 0.7319\n",
      "Epoch #14500 Loss: 0.5343 accuracy: 0.7315\n",
      "Epoch #15000 Loss: 0.5315 accuracy: 0.7315\n",
      "Epoch #15500 Loss: 0.5221 accuracy: 0.7396\n",
      "Epoch #16000 Loss: 0.5219 accuracy: 0.7361\n",
      "Epoch #16500 Loss: 0.5198 accuracy: 0.7374\n",
      "Epoch #17000 Loss: 0.5184 accuracy: 0.7383\n",
      "Epoch #17500 Loss: 0.5148 accuracy: 0.7400\n",
      "Epoch #18000 Loss: 0.5127 accuracy: 0.7396\n",
      "Epoch #18500 Loss: 0.5119 accuracy: 0.7400\n",
      "Epoch #19000 Loss: 0.5084 accuracy: 0.7460\n",
      "Epoch #19500 Loss: 0.5072 accuracy: 0.7468\n",
      "Epoch #20000 Loss: 0.5073 accuracy: 0.7472\n",
      "Epoch #20500 Loss: 0.5020 accuracy: 0.7515\n",
      "Epoch #21000 Loss: 0.4988 accuracy: 0.7519\n",
      "Epoch #21500 Loss: 0.5052 accuracy: 0.7485\n",
      "Epoch #22000 Loss: 0.4909 accuracy: 0.7575\n",
      "Epoch #22500 Loss: 0.4985 accuracy: 0.7562\n",
      "Epoch #23000 Loss: 0.4979 accuracy: 0.7579\n",
      "Epoch #23500 Loss: 0.4987 accuracy: 0.7549\n",
      "Epoch #24000 Loss: 0.4884 accuracy: 0.7600\n",
      "Epoch #24500 Loss: 0.4893 accuracy: 0.7604\n",
      "Epoch #25000 Loss: 0.4903 accuracy: 0.7596\n",
      "Epoch #25500 Loss: 0.4923 accuracy: 0.7566\n",
      "Epoch #26000 Loss: 0.4855 accuracy: 0.7639\n",
      "Epoch #26500 Loss: 0.4839 accuracy: 0.7647\n",
      "Epoch #27000 Loss: 0.4755 accuracy: 0.7698\n",
      "Epoch #27500 Loss: 0.4867 accuracy: 0.7596\n",
      "Epoch #28000 Loss: 0.4753 accuracy: 0.7698\n",
      "Epoch #28500 Loss: 0.4755 accuracy: 0.7690\n",
      "Epoch #29000 Loss: 0.4883 accuracy: 0.7549\n",
      "Epoch #29500 Loss: 0.4740 accuracy: 0.7720\n",
      "Epoch #30000 Loss: 0.4749 accuracy: 0.7673\n",
      "Epoch #30500 Loss: 0.4762 accuracy: 0.7673\n",
      "Epoch #31000 Loss: 0.4736 accuracy: 0.7707\n",
      "Epoch #31500 Loss: 0.4718 accuracy: 0.7702\n",
      "Epoch #32000 Loss: 0.4731 accuracy: 0.7715\n",
      "Epoch #32500 Loss: 0.4705 accuracy: 0.7732\n",
      "Epoch #33000 Loss: 0.4634 accuracy: 0.7766\n",
      "Epoch #33500 Loss: 0.4619 accuracy: 0.7741\n",
      "Epoch #34000 Loss: 0.4736 accuracy: 0.7673\n",
      "Epoch #34500 Loss: 0.4596 accuracy: 0.7801\n",
      "Epoch #35000 Loss: 0.4731 accuracy: 0.7728\n",
      "Epoch #35500 Loss: 0.4670 accuracy: 0.7720\n",
      "Epoch #36000 Loss: 0.4735 accuracy: 0.7690\n",
      "Epoch #36500 Loss: 0.4666 accuracy: 0.7749\n",
      "Epoch #37000 Loss: 0.4517 accuracy: 0.7771\n",
      "Epoch #37500 Loss: 0.4631 accuracy: 0.7801\n",
      "Epoch #38000 Loss: 0.4489 accuracy: 0.7737\n",
      "Epoch #38500 Loss: 0.4607 accuracy: 0.7805\n",
      "Epoch #39000 Loss: 0.4628 accuracy: 0.7745\n",
      "Epoch #39500 Loss: 0.4545 accuracy: 0.7869\n",
      "Epoch #40000 Loss: 0.4659 accuracy: 0.7664\n",
      "Epoch #40500 Loss: 0.4451 accuracy: 0.7783\n",
      "Epoch #41000 Loss: 0.4587 accuracy: 0.7805\n",
      "Epoch #41500 Loss: 0.4733 accuracy: 0.7762\n",
      "Epoch #42000 Loss: 0.4578 accuracy: 0.7698\n",
      "Epoch #42500 Loss: 0.4475 accuracy: 0.7771\n",
      "Epoch #43000 Loss: 0.4354 accuracy: 0.7852\n",
      "Epoch #43500 Loss: 0.4421 accuracy: 0.7864\n",
      "Epoch #44000 Loss: 0.4522 accuracy: 0.7873\n",
      "Epoch #44500 Loss: 0.4858 accuracy: 0.7634\n",
      "Epoch #45000 Loss: 0.4321 accuracy: 0.7967\n",
      "Epoch #45500 Loss: 0.4514 accuracy: 0.7852\n",
      "Epoch #46000 Loss: 0.4211 accuracy: 0.8026\n",
      "Epoch #46500 Loss: 0.4223 accuracy: 0.8001\n",
      "Epoch #47000 Loss: 0.4400 accuracy: 0.8026\n",
      "Epoch #47500 Loss: 0.4479 accuracy: 0.7783\n",
      "Epoch #48000 Loss: 0.4596 accuracy: 0.7813\n",
      "Epoch #48500 Loss: 0.4168 accuracy: 0.7950\n",
      "Epoch #49000 Loss: 0.4453 accuracy: 0.7873\n",
      "Epoch #49500 Loss: 0.4128 accuracy: 0.7980\n",
      "Epoch #50000 Loss: 0.4249 accuracy: 0.8035\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 50000\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        epoch_loss, epoch_accuracy,epoch_output, _ = sess.run([loss, accuracy,output, train_step],feed_dict={x_input: \n",
    "                                                                                         features,y: labels,})\n",
    "        if (epoch+1)% 500 == 0:\n",
    "            print(\"Epoch #{}\".format(epoch+1), \"Loss: {:.4f}\".format(epoch_loss), \n",
    "                  \"accuracy: {:.4f}\".format(epoch_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "713.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(epoch_output).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1108.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
