{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy.io import arff\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_data = scipy.io.arff.loadarff(\"/home/karim/Documents/research/MLML datasets/emotions/emotions.arff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_labels = emotions_data[0]\n",
    "features_labels_df = pd.DataFrame(features_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features_labels_df.values[:,:-6]\n",
    "labels = features_labels_df.values[:,-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "input_shape = 72\n",
    "output_shape = 6\n",
    "hidden_layer_1_shape = 48\n",
    "hidden_layer_2_shape = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "code_folding": [
     0,
     5,
     11
    ]
   },
   "outputs": [],
   "source": [
    "def get_weights(shape):\n",
    "    w = tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "    #variable_summaries(w)\n",
    "    return w\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    b = tf.Variable(initial)\n",
    "    #variable_summaries(b)\n",
    "    return b\n",
    "\n",
    "def full_layer(input, size):\n",
    "    in_size = int(input.get_shape()[1])\n",
    "    W = get_weights([in_size, size])\n",
    "    b = bias_variable([size])\n",
    "    return tf.matmul(input, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a 2 layers network to train \n",
    "y = tf.placeholder(tf.float32, [None, output_shape], name=\"true_labels\")\n",
    "x_input = tf.placeholder(tf.float32, [None,input_shape],name=\"input_layer\")\n",
    "h1 = tf.nn.sigmoid(full_layer(x_input, hidden_layer_1_shape))\n",
    "h2 = tf.nn.sigmoid(full_layer(h1, hidden_layer_2_shape))\n",
    "logits = full_layer(h2,output_shape)\n",
    "output = tf.nn.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "train_step = tf.train.AdadeltaOptimizer(0.01).minimize(loss)\n",
    "correct_prediction = tf.equal(tf.round(output), y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #100 Loss: 0.7193 accuracy: 0.4553\n",
      "Epoch #200 Loss: 0.7168 accuracy: 0.4553\n",
      "Epoch #300 Loss: 0.7141 accuracy: 0.4553\n",
      "Epoch #400 Loss: 0.7114 accuracy: 0.4553\n",
      "Epoch #500 Loss: 0.7085 accuracy: 0.4553\n",
      "Epoch #600 Loss: 0.7056 accuracy: 0.4553\n",
      "Epoch #700 Loss: 0.7026 accuracy: 0.4553\n",
      "Epoch #800 Loss: 0.6995 accuracy: 0.4553\n",
      "Epoch #900 Loss: 0.6962 accuracy: 0.4553\n",
      "Epoch #1000 Loss: 0.6931 accuracy: 0.4553\n",
      "Epoch #1100 Loss: 0.6901 accuracy: 0.4553\n",
      "Epoch #1200 Loss: 0.6872 accuracy: 0.4553\n",
      "Epoch #1300 Loss: 0.6843 accuracy: 0.4553\n",
      "Epoch #1400 Loss: 0.6814 accuracy: 0.4553\n",
      "Epoch #1500 Loss: 0.6785 accuracy: 0.4553\n",
      "Epoch #1600 Loss: 0.6757 accuracy: 0.4935\n",
      "Epoch #1700 Loss: 0.6729 accuracy: 0.5467\n",
      "Epoch #1800 Loss: 0.6702 accuracy: 0.6127\n",
      "Epoch #1900 Loss: 0.6672 accuracy: 0.6152\n",
      "Epoch #2000 Loss: 0.6645 accuracy: 0.6799\n",
      "Epoch #2100 Loss: 0.6619 accuracy: 0.6883\n",
      "Epoch #2200 Loss: 0.6594 accuracy: 0.6886\n",
      "Epoch #2300 Loss: 0.6569 accuracy: 0.6886\n",
      "Epoch #2400 Loss: 0.6545 accuracy: 0.6886\n",
      "Epoch #2500 Loss: 0.6522 accuracy: 0.6886\n",
      "Epoch #2600 Loss: 0.6499 accuracy: 0.6886\n",
      "Epoch #2700 Loss: 0.6477 accuracy: 0.6886\n",
      "Epoch #2800 Loss: 0.6456 accuracy: 0.6886\n",
      "Epoch #2900 Loss: 0.6435 accuracy: 0.6886\n",
      "Epoch #3000 Loss: 0.6415 accuracy: 0.6886\n",
      "Epoch #3100 Loss: 0.6396 accuracy: 0.6886\n",
      "Epoch #3200 Loss: 0.6378 accuracy: 0.6886\n",
      "Epoch #3300 Loss: 0.6360 accuracy: 0.6886\n",
      "Epoch #3400 Loss: 0.6344 accuracy: 0.6886\n",
      "Epoch #3500 Loss: 0.6328 accuracy: 0.6886\n",
      "Epoch #3600 Loss: 0.6312 accuracy: 0.6886\n",
      "Epoch #3700 Loss: 0.6298 accuracy: 0.6886\n",
      "Epoch #3800 Loss: 0.6284 accuracy: 0.6886\n",
      "Epoch #3900 Loss: 0.6271 accuracy: 0.6886\n",
      "Epoch #4000 Loss: 0.6258 accuracy: 0.6886\n",
      "Epoch #4100 Loss: 0.6247 accuracy: 0.6886\n",
      "Epoch #4200 Loss: 0.6236 accuracy: 0.6886\n",
      "Epoch #4300 Loss: 0.6225 accuracy: 0.6886\n",
      "Epoch #4400 Loss: 0.6216 accuracy: 0.6886\n",
      "Epoch #4500 Loss: 0.6207 accuracy: 0.6886\n",
      "Epoch #4600 Loss: 0.6198 accuracy: 0.6886\n",
      "Epoch #4700 Loss: 0.6190 accuracy: 0.6886\n",
      "Epoch #4800 Loss: 0.6183 accuracy: 0.6886\n",
      "Epoch #4900 Loss: 0.6176 accuracy: 0.6886\n",
      "Epoch #5000 Loss: 0.6169 accuracy: 0.6886\n",
      "Epoch #5100 Loss: 0.6163 accuracy: 0.6886\n",
      "Epoch #5200 Loss: 0.6158 accuracy: 0.6886\n",
      "Epoch #5300 Loss: 0.6153 accuracy: 0.6886\n",
      "Epoch #5400 Loss: 0.6148 accuracy: 0.6886\n",
      "Epoch #5500 Loss: 0.6144 accuracy: 0.6886\n",
      "Epoch #5600 Loss: 0.6140 accuracy: 0.6886\n",
      "Epoch #5700 Loss: 0.6136 accuracy: 0.6886\n",
      "Epoch #5800 Loss: 0.6133 accuracy: 0.6886\n",
      "Epoch #5900 Loss: 0.6130 accuracy: 0.6886\n",
      "Epoch #6000 Loss: 0.6127 accuracy: 0.6886\n",
      "Epoch #6100 Loss: 0.6125 accuracy: 0.6886\n",
      "Epoch #6200 Loss: 0.6123 accuracy: 0.6886\n",
      "Epoch #6300 Loss: 0.6121 accuracy: 0.6886\n",
      "Epoch #6400 Loss: 0.6119 accuracy: 0.6886\n",
      "Epoch #6500 Loss: 0.6118 accuracy: 0.6886\n",
      "Epoch #6600 Loss: 0.6117 accuracy: 0.6886\n",
      "Epoch #6700 Loss: 0.6116 accuracy: 0.6886\n",
      "Epoch #6800 Loss: 0.6115 accuracy: 0.6886\n",
      "Epoch #6900 Loss: 0.6114 accuracy: 0.6886\n",
      "Epoch #7000 Loss: 0.6113 accuracy: 0.6886\n",
      "Epoch #7100 Loss: 0.6112 accuracy: 0.6886\n",
      "Epoch #7200 Loss: 0.6111 accuracy: 0.6886\n",
      "Epoch #7300 Loss: 0.6111 accuracy: 0.6886\n",
      "Epoch #7400 Loss: 0.6110 accuracy: 0.6886\n",
      "Epoch #7500 Loss: 0.6110 accuracy: 0.6886\n",
      "Epoch #7600 Loss: 0.6110 accuracy: 0.6886\n",
      "Epoch #7700 Loss: 0.6110 accuracy: 0.6886\n",
      "Epoch #7800 Loss: 0.6109 accuracy: 0.6886\n",
      "Epoch #7900 Loss: 0.6109 accuracy: 0.6886\n",
      "Epoch #8000 Loss: 0.6109 accuracy: 0.6886\n",
      "Epoch #8100 Loss: 0.6109 accuracy: 0.6886\n",
      "Epoch #8200 Loss: 0.6109 accuracy: 0.6886\n",
      "Epoch #8300 Loss: 0.6109 accuracy: 0.6886\n",
      "Epoch #8400 Loss: 0.6109 accuracy: 0.6886\n",
      "Epoch #8500 Loss: 0.6109 accuracy: 0.6886\n",
      "Epoch #8600 Loss: 0.6109 accuracy: 0.6886\n",
      "Epoch #8700 Loss: 0.6109 accuracy: 0.6886\n",
      "Epoch #8800 Loss: 0.6108 accuracy: 0.6886\n",
      "Epoch #8900 Loss: 0.6108 accuracy: 0.6886\n",
      "Epoch #9000 Loss: 0.6108 accuracy: 0.6886\n",
      "Epoch #9100 Loss: 0.6108 accuracy: 0.6886\n",
      "Epoch #9200 Loss: 0.6108 accuracy: 0.6886\n",
      "Epoch #9300 Loss: 0.6108 accuracy: 0.6886\n",
      "Epoch #9400 Loss: 0.6108 accuracy: 0.6886\n",
      "Epoch #9500 Loss: 0.6108 accuracy: 0.6886\n",
      "Epoch #9600 Loss: 0.6108 accuracy: 0.6886\n",
      "Epoch #9700 Loss: 0.6108 accuracy: 0.6886\n",
      "Epoch #9800 Loss: 0.6108 accuracy: 0.6886\n",
      "Epoch #9900 Loss: 0.6108 accuracy: 0.6886\n",
      "Epoch #10000 Loss: 0.6108 accuracy: 0.6886\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 10000\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        epoch_loss, epoch_accuracy,epoch_output, _ = sess.run([loss, accuracy,output, train_step],feed_dict={x_input: \n",
    "                                                                                         features,y: labels,})\n",
    "        if (epoch+1)% 100 == 0:\n",
    "            print(\"Epoch #{}\".format(epoch+1), \"Loss: {:.4f}\".format(epoch_loss), \n",
    "                  \"accuracy: {:.4f}\".format(epoch_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
