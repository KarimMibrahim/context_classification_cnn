{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples is: 391\n",
      "Number of test samples is: 202\n"
     ]
    }
   ],
   "source": [
    "emotions_data_train = scipy.io.arff.loadarff(\"/home/karim/Documents/research/MLML datasets/emotions/emotions-train.arff\")\n",
    "emotions_data_test = scipy.io.arff.loadarff(\"/home/karim/Documents/research/MLML datasets/emotions/emotions-test.arff\")\n",
    "features_labels = emotions_data_train[0]\n",
    "features_labels_df = pd.DataFrame(features_labels)\n",
    "print(\"Number of training samples is: {}\".format(len(emotions_data[0])))\n",
    "\n",
    "features_labels_test = emotions_data_test[0]\n",
    "features_labels_test_df = pd.DataFrame(features_labels_test)\n",
    "print(\"Number of test samples is: {}\".format(len(features_labels__test_df)))\n",
    "features = features_labels_df.values[:,:-6]\n",
    "labels = features_labels_df.values[:,-6:]\n",
    "test_features = features_labels_test_df.values[:,:-6]\n",
    "test_labels = features_labels_test_df.values[:,-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "code_folding": [
     5,
     10,
     16
    ]
   },
   "outputs": [],
   "source": [
    "input_shape = 72\n",
    "output_shape = 6\n",
    "hidden_layer_1_shape = 48\n",
    "hidden_layer_2_shape = 24\n",
    "\n",
    "def get_weights(shape):\n",
    "    w = tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "    #variable_summaries(w)\n",
    "    return w\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    b = tf.Variable(initial)\n",
    "    #variable_summaries(b)\n",
    "    return b\n",
    "\n",
    "def full_layer(input, size):\n",
    "    in_size = int(input.get_shape()[1])\n",
    "    W = get_weights([in_size, size])\n",
    "    b = bias_variable([size])\n",
    "    return tf.matmul(input, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a 2 layers network to train \n",
    "y = tf.placeholder(tf.float32, [None, output_shape], name=\"true_labels\")\n",
    "x_input = tf.placeholder(tf.float32, [None,input_shape],name=\"input_layer\")\n",
    "h1 = tf.nn.relu(full_layer(x_input, hidden_layer_1_shape))\n",
    "h2 = tf.nn.relu(full_layer(h1, hidden_layer_2_shape))\n",
    "#h3 = tf.nn.relu(full_layer(h2, hidden_layer_2_shape))\n",
    "#h4 = tf.nn.relu(full_layer(h3, hidden_layer_2_shape))\n",
    "logits = full_layer(h2,output_shape)\n",
    "output = tf.nn.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "# Learning rate decay\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "learning_rate = tf.train.exponential_decay(learning_rate=0.1, global_step=global_step, decay_steps=1000,\n",
    "                                          decay_rate=0.95,staircase=True)\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=global_step)\n",
    "correct_prediction = tf.equal(tf.round(output), y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #500 Loss: 0.6067 accuracy: 0.6748 Test loss: 0.6229 Test accuracy: 0.6733 Learning rate: 0.10000000149011612\n",
      "Epoch #1000 Loss: 0.5892 accuracy: 0.7033 Test loss: 0.5976 Test accuracy: 0.7046 Learning rate: 0.10000000149011612\n",
      "Epoch #1500 Loss: 0.5825 accuracy: 0.7097 Test loss: 0.6235 Test accuracy: 0.6757 Learning rate: 0.10000000149011612\n",
      "Epoch #2000 Loss: 0.5889 accuracy: 0.7029 Test loss: 0.6193 Test accuracy: 0.6749 Learning rate: 0.10000000149011612\n",
      "Epoch #2500 Loss: 0.5882 accuracy: 0.7204 Test loss: 0.6146 Test accuracy: 0.6774 Learning rate: 0.10000000149011612\n",
      "Epoch #3000 Loss: 0.5817 accuracy: 0.7038 Test loss: 0.6012 Test accuracy: 0.7054 Learning rate: 0.10000000149011612\n",
      "Epoch #3500 Loss: 0.5709 accuracy: 0.7131 Test loss: 0.5825 Test accuracy: 0.7087 Learning rate: 0.10000000149011612\n",
      "Epoch #4000 Loss: 0.5985 accuracy: 0.7038 Test loss: 0.5942 Test accuracy: 0.7087 Learning rate: 0.10000000149011612\n",
      "Epoch #4500 Loss: 0.5580 accuracy: 0.7123 Test loss: 0.5703 Test accuracy: 0.7178 Learning rate: 0.10000000149011612\n",
      "Epoch #5000 Loss: 0.5683 accuracy: 0.7165 Test loss: 0.5683 Test accuracy: 0.7079 Learning rate: 0.10000000149011612\n",
      "Epoch #5500 Loss: 0.5692 accuracy: 0.7144 Test loss: 0.5765 Test accuracy: 0.7030 Learning rate: 0.10000000149011612\n",
      "Epoch #6000 Loss: 0.5399 accuracy: 0.7387 Test loss: 0.6558 Test accuracy: 0.6865 Learning rate: 0.10000000149011612\n",
      "Epoch #6500 Loss: 0.5321 accuracy: 0.7400 Test loss: 0.5892 Test accuracy: 0.7013 Learning rate: 0.10000000149011612\n",
      "Epoch #7000 Loss: 0.5621 accuracy: 0.7310 Test loss: 0.6180 Test accuracy: 0.6766 Learning rate: 0.10000000149011612\n",
      "Epoch #7500 Loss: 0.5647 accuracy: 0.7187 Test loss: 0.5776 Test accuracy: 0.7096 Learning rate: 0.10000000149011612\n",
      "Epoch #8000 Loss: 0.4996 accuracy: 0.7421 Test loss: 0.5521 Test accuracy: 0.7137 Learning rate: 0.10000000149011612\n",
      "Epoch #8500 Loss: 0.5497 accuracy: 0.7323 Test loss: 0.6195 Test accuracy: 0.6906 Learning rate: 0.10000000149011612\n",
      "Epoch #9000 Loss: 0.4959 accuracy: 0.7447 Test loss: 0.5628 Test accuracy: 0.7063 Learning rate: 0.10000000149011612\n",
      "Epoch #9500 Loss: 0.4927 accuracy: 0.7536 Test loss: 0.5415 Test accuracy: 0.7145 Learning rate: 0.10000000149011612\n",
      "Epoch #10000 Loss: 0.4966 accuracy: 0.7519 Test loss: 0.5888 Test accuracy: 0.7030 Learning rate: 0.10000000149011612\n",
      "Epoch #10500 Loss: 0.5492 accuracy: 0.7251 Test loss: 0.5433 Test accuracy: 0.7120 Learning rate: 0.10000000149011612\n",
      "Epoch #11000 Loss: 0.4921 accuracy: 0.7485 Test loss: 0.5409 Test accuracy: 0.7203 Learning rate: 0.10000000149011612\n",
      "Epoch #11500 Loss: 0.4858 accuracy: 0.7558 Test loss: 0.5296 Test accuracy: 0.7261 Learning rate: 0.10000000149011612\n",
      "Epoch #12000 Loss: 0.4747 accuracy: 0.7673 Test loss: 0.5307 Test accuracy: 0.7228 Learning rate: 0.10000000149011612\n",
      "Epoch #12500 Loss: 0.4795 accuracy: 0.7626 Test loss: 0.5435 Test accuracy: 0.7178 Learning rate: 0.10000000149011612\n",
      "Epoch #13000 Loss: 0.4842 accuracy: 0.7621 Test loss: 0.5524 Test accuracy: 0.7112 Learning rate: 0.10000000149011612\n",
      "Epoch #13500 Loss: 0.5170 accuracy: 0.7417 Test loss: 0.5692 Test accuracy: 0.7104 Learning rate: 0.10000000149011612\n",
      "Epoch #14000 Loss: 0.4990 accuracy: 0.7468 Test loss: 0.5347 Test accuracy: 0.7236 Learning rate: 0.10000000149011612\n",
      "Epoch #14500 Loss: 0.4836 accuracy: 0.7643 Test loss: 0.5655 Test accuracy: 0.7120 Learning rate: 0.10000000149011612\n",
      "Epoch #15000 Loss: 0.5106 accuracy: 0.7477 Test loss: 0.5399 Test accuracy: 0.7219 Learning rate: 0.10000000149011612\n",
      "Epoch #15500 Loss: 0.4827 accuracy: 0.7596 Test loss: 0.5330 Test accuracy: 0.7244 Learning rate: 0.10000000149011612\n",
      "Epoch #16000 Loss: 0.5191 accuracy: 0.7442 Test loss: 0.5387 Test accuracy: 0.7343 Learning rate: 0.10000000149011612\n",
      "Epoch #16500 Loss: 0.4739 accuracy: 0.7660 Test loss: 0.5197 Test accuracy: 0.7450 Learning rate: 0.10000000149011612\n",
      "Epoch #17000 Loss: 0.4664 accuracy: 0.7737 Test loss: 0.5478 Test accuracy: 0.7236 Learning rate: 0.10000000149011612\n",
      "Epoch #17500 Loss: 0.5239 accuracy: 0.7280 Test loss: 0.5297 Test accuracy: 0.7475 Learning rate: 0.10000000149011612\n",
      "Epoch #18000 Loss: 0.4685 accuracy: 0.7681 Test loss: 0.5156 Test accuracy: 0.7459 Learning rate: 0.10000000149011612\n",
      "Epoch #18500 Loss: 0.4870 accuracy: 0.7562 Test loss: 0.5202 Test accuracy: 0.7475 Learning rate: 0.10000000149011612\n",
      "Epoch #19000 Loss: 0.5254 accuracy: 0.7293 Test loss: 0.5276 Test accuracy: 0.7459 Learning rate: 0.10000000149011612\n",
      "Epoch #19500 Loss: 0.5222 accuracy: 0.7400 Test loss: 0.5437 Test accuracy: 0.7393 Learning rate: 0.10000000149011612\n",
      "Epoch #20000 Loss: 0.4615 accuracy: 0.7771 Test loss: 0.5142 Test accuracy: 0.7409 Learning rate: 0.10000000149011612\n",
      "Epoch #20500 Loss: 0.4584 accuracy: 0.7783 Test loss: 0.5429 Test accuracy: 0.7211 Learning rate: 0.10000000149011612\n",
      "Epoch #21000 Loss: 0.4506 accuracy: 0.7813 Test loss: 0.5108 Test accuracy: 0.7492 Learning rate: 0.10000000149011612\n",
      "Epoch #21500 Loss: 0.4582 accuracy: 0.7809 Test loss: 0.5242 Test accuracy: 0.7343 Learning rate: 0.10000000149011612\n",
      "Epoch #22000 Loss: 0.4587 accuracy: 0.7826 Test loss: 0.5323 Test accuracy: 0.7277 Learning rate: 0.10000000149011612\n",
      "Epoch #22500 Loss: 0.4723 accuracy: 0.7732 Test loss: 0.5175 Test accuracy: 0.7533 Learning rate: 0.10000000149011612\n",
      "Epoch #23000 Loss: 0.4566 accuracy: 0.7809 Test loss: 0.5640 Test accuracy: 0.7178 Learning rate: 0.10000000149011612\n",
      "Epoch #23500 Loss: 0.4749 accuracy: 0.7741 Test loss: 0.6015 Test accuracy: 0.7046 Learning rate: 0.10000000149011612\n",
      "Epoch #24000 Loss: 0.4725 accuracy: 0.7694 Test loss: 0.5194 Test accuracy: 0.7558 Learning rate: 0.10000000149011612\n",
      "Epoch #24500 Loss: 0.4747 accuracy: 0.7685 Test loss: 0.5578 Test accuracy: 0.7178 Learning rate: 0.10000000149011612\n",
      "Epoch #25000 Loss: 0.4559 accuracy: 0.7822 Test loss: 0.5764 Test accuracy: 0.7145 Learning rate: 0.10000000149011612\n",
      "Epoch #25500 Loss: 0.4350 accuracy: 0.7945 Test loss: 0.5022 Test accuracy: 0.7508 Learning rate: 0.10000000149011612\n",
      "Epoch #26000 Loss: 0.5043 accuracy: 0.7506 Test loss: 0.5643 Test accuracy: 0.7137 Learning rate: 0.10000000149011612\n",
      "Epoch #26500 Loss: 0.4562 accuracy: 0.7783 Test loss: 0.5386 Test accuracy: 0.7351 Learning rate: 0.10000000149011612\n",
      "Epoch #27000 Loss: 0.4770 accuracy: 0.7579 Test loss: 0.5211 Test accuracy: 0.7310 Learning rate: 0.10000000149011612\n",
      "Epoch #27500 Loss: 0.4496 accuracy: 0.7864 Test loss: 0.5239 Test accuracy: 0.7368 Learning rate: 0.10000000149011612\n",
      "Epoch #28000 Loss: 0.4604 accuracy: 0.7788 Test loss: 0.5708 Test accuracy: 0.7203 Learning rate: 0.10000000149011612\n",
      "Epoch #28500 Loss: 0.4462 accuracy: 0.7801 Test loss: 0.5181 Test accuracy: 0.7409 Learning rate: 0.10000000149011612\n",
      "Epoch #29000 Loss: 0.4486 accuracy: 0.7830 Test loss: 0.5209 Test accuracy: 0.7335 Learning rate: 0.10000000149011612\n",
      "Epoch #29500 Loss: 0.4544 accuracy: 0.7835 Test loss: 0.5746 Test accuracy: 0.7137 Learning rate: 0.10000000149011612\n",
      "Epoch #30000 Loss: 0.4350 accuracy: 0.7967 Test loss: 0.4988 Test accuracy: 0.7558 Learning rate: 0.10000000149011612\n",
      "Epoch #30500 Loss: 0.4350 accuracy: 0.7916 Test loss: 0.5169 Test accuracy: 0.7442 Learning rate: 0.10000000149011612\n",
      "Epoch #31000 Loss: 0.4308 accuracy: 0.7967 Test loss: 0.5390 Test accuracy: 0.7327 Learning rate: 0.10000000149011612\n",
      "Epoch #31500 Loss: 0.4472 accuracy: 0.7864 Test loss: 0.5107 Test accuracy: 0.7508 Learning rate: 0.10000000149011612\n",
      "Epoch #32000 Loss: 0.4543 accuracy: 0.7766 Test loss: 0.5360 Test accuracy: 0.7219 Learning rate: 0.10000000149011612\n",
      "Epoch #32500 Loss: 0.5367 accuracy: 0.7417 Test loss: 0.5175 Test accuracy: 0.7475 Learning rate: 0.10000000149011612\n",
      "Epoch #33000 Loss: 0.4333 accuracy: 0.7933 Test loss: 0.5296 Test accuracy: 0.7459 Learning rate: 0.10000000149011612\n",
      "Epoch #33500 Loss: 0.4722 accuracy: 0.7647 Test loss: 0.5092 Test accuracy: 0.7533 Learning rate: 0.10000000149011612\n",
      "Epoch #34000 Loss: 0.4467 accuracy: 0.7873 Test loss: 0.5691 Test accuracy: 0.7178 Learning rate: 0.10000000149011612\n",
      "Epoch #34500 Loss: 0.4554 accuracy: 0.7818 Test loss: 0.5638 Test accuracy: 0.7203 Learning rate: 0.10000000149011612\n",
      "Epoch #35000 Loss: 0.4295 accuracy: 0.8014 Test loss: 0.5145 Test accuracy: 0.7517 Learning rate: 0.10000000149011612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #35500 Loss: 0.4581 accuracy: 0.7830 Test loss: 0.5787 Test accuracy: 0.7285 Learning rate: 0.10000000149011612\n",
      "Epoch #36000 Loss: 0.4630 accuracy: 0.7728 Test loss: 0.6178 Test accuracy: 0.7071 Learning rate: 0.10000000149011612\n",
      "Epoch #36500 Loss: 0.4656 accuracy: 0.7651 Test loss: 0.5553 Test accuracy: 0.7170 Learning rate: 0.10000000149011612\n",
      "Epoch #37000 Loss: 0.4482 accuracy: 0.7830 Test loss: 0.5173 Test accuracy: 0.7525 Learning rate: 0.10000000149011612\n",
      "Epoch #37500 Loss: 0.4399 accuracy: 0.7890 Test loss: 0.5437 Test accuracy: 0.7401 Learning rate: 0.10000000149011612\n",
      "Epoch #38000 Loss: 0.4367 accuracy: 0.7890 Test loss: 0.5234 Test accuracy: 0.7541 Learning rate: 0.10000000149011612\n",
      "Epoch #38500 Loss: 0.4522 accuracy: 0.7796 Test loss: 0.5889 Test accuracy: 0.7236 Learning rate: 0.10000000149011612\n",
      "Epoch #39000 Loss: 0.4632 accuracy: 0.7766 Test loss: 0.5336 Test accuracy: 0.7351 Learning rate: 0.10000000149011612\n",
      "Epoch #39500 Loss: 0.4333 accuracy: 0.7958 Test loss: 0.5206 Test accuracy: 0.7409 Learning rate: 0.10000000149011612\n",
      "Epoch #40000 Loss: 0.4504 accuracy: 0.7860 Test loss: 0.5309 Test accuracy: 0.7360 Learning rate: 0.10000000149011612\n",
      "Epoch #40500 Loss: 0.4545 accuracy: 0.7847 Test loss: 0.5760 Test accuracy: 0.7236 Learning rate: 0.10000000149011612\n",
      "Epoch #41000 Loss: 0.4374 accuracy: 0.7920 Test loss: 0.5877 Test accuracy: 0.7170 Learning rate: 0.10000000149011612\n",
      "Epoch #41500 Loss: 0.4793 accuracy: 0.7617 Test loss: 0.5098 Test accuracy: 0.7467 Learning rate: 0.10000000149011612\n",
      "Epoch #42000 Loss: 0.4362 accuracy: 0.7907 Test loss: 0.5170 Test accuracy: 0.7591 Learning rate: 0.10000000149011612\n",
      "Epoch #42500 Loss: 0.4731 accuracy: 0.7660 Test loss: 0.5404 Test accuracy: 0.7442 Learning rate: 0.10000000149011612\n",
      "Epoch #43000 Loss: 0.4212 accuracy: 0.8022 Test loss: 0.5552 Test accuracy: 0.7368 Learning rate: 0.10000000149011612\n",
      "Epoch #43500 Loss: 0.4205 accuracy: 0.8026 Test loss: 0.5291 Test accuracy: 0.7483 Learning rate: 0.10000000149011612\n",
      "Epoch #44000 Loss: 0.4368 accuracy: 0.7894 Test loss: 0.5352 Test accuracy: 0.7376 Learning rate: 0.10000000149011612\n",
      "Epoch #44500 Loss: 0.5198 accuracy: 0.7387 Test loss: 0.5285 Test accuracy: 0.7426 Learning rate: 0.10000000149011612\n",
      "Epoch #45000 Loss: 0.4458 accuracy: 0.7856 Test loss: 0.5545 Test accuracy: 0.7401 Learning rate: 0.10000000149011612\n",
      "Epoch #45500 Loss: 0.4197 accuracy: 0.8009 Test loss: 0.5204 Test accuracy: 0.7533 Learning rate: 0.10000000149011612\n",
      "Epoch #46000 Loss: 0.4767 accuracy: 0.7690 Test loss: 0.6930 Test accuracy: 0.6955 Learning rate: 0.10000000149011612\n",
      "Epoch #46500 Loss: 0.4285 accuracy: 0.7984 Test loss: 0.5472 Test accuracy: 0.7533 Learning rate: 0.10000000149011612\n",
      "Epoch #47000 Loss: 0.4512 accuracy: 0.7783 Test loss: 0.6441 Test accuracy: 0.7129 Learning rate: 0.10000000149011612\n",
      "Epoch #47500 Loss: 0.4286 accuracy: 0.7873 Test loss: 0.5625 Test accuracy: 0.7327 Learning rate: 0.10000000149011612\n",
      "Epoch #48000 Loss: 0.4585 accuracy: 0.7762 Test loss: 0.5884 Test accuracy: 0.7252 Learning rate: 0.10000000149011612\n",
      "Epoch #48500 Loss: 0.4209 accuracy: 0.7928 Test loss: 0.5534 Test accuracy: 0.7384 Learning rate: 0.10000000149011612\n",
      "Epoch #49000 Loss: 0.4292 accuracy: 0.7860 Test loss: 0.5748 Test accuracy: 0.7450 Learning rate: 0.10000000149011612\n",
      "Epoch #49500 Loss: 0.4885 accuracy: 0.7613 Test loss: 0.5639 Test accuracy: 0.7277 Learning rate: 0.10000000149011612\n",
      "Epoch #50000 Loss: 0.4388 accuracy: 0.7843 Test loss: 0.6259 Test accuracy: 0.7310 Learning rate: 0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 50000\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        epoch_loss, epoch_accuracy,epoch_output, _ = sess.run([loss, accuracy,output, train_step],feed_dict={x_input: \n",
    "                                                                                         features,y: labels,})\n",
    "        if (epoch+1)% 500 == 0:\n",
    "            val_losses, val_accuracies, val_output,current_learning_rate = sess.run([loss, accuracy,output,learning_rate],feed_dict={\n",
    "                                                                                          x_input: test_features,\n",
    "                                                                                          y:test_labels})\n",
    "            print(\"Epoch #{}\".format(epoch+1), \"Loss: {:.4f}\".format(epoch_loss), \n",
    "                  \"accuracy: {:.4f}\".format(epoch_accuracy), \n",
    "                  \"Test loss: {:.4f}\".format(val_losses), \n",
    "                  \"Test accuracy: {:.4f}\".format(val_accuracies), \"Learning rate: {}\".format(current_learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
